{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets \n",
    "train_labels = np.array(pd.read_csv(\"../datasets/train_labels.csv\", delimiter=\",\", header=0, index_col=0))\n",
    "train_images = np.load(\"../datasets/train_images.npy\", encoding=\"latin1\")\n",
    "test_images = np.load(\"../datasets/test_images.npy\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPROCESSING IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape(dataset):\n",
    "    '''Reshape images from dimension 10000 --> 100*100\n",
    "    :param dataset: \n",
    "    '''\n",
    "    output = []\n",
    "    for img in dataset:\n",
    "        output.append(img.reshape(100,100))\n",
    "    return np.array(output, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unravel(dataset):\n",
    "    '''Reshape images from dimension 100*100 --> 10000\n",
    "    :param dataset: \n",
    "    '''\n",
    "    output = []\n",
    "    for img in dataset:\n",
    "        output.append(img.ravel())\n",
    "    return np.array(output, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareToSaveNPY(dataset):\n",
    "    '''Convert numpy array to format previously saved in .npy\n",
    "    :param dataset: \n",
    "    '''\n",
    "    output = []\n",
    "    for i in range(len(dataset)):\n",
    "        output.append((int(i), np.array(dataset[i], dtype=float)))\n",
    "    return np.array(output, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize(dataset, threshold):\n",
    "    '''Convert greyscale to binary according to threshold\n",
    "    :param dataset:\n",
    "    :param threshold:\n",
    "    '''\n",
    "    output = []\n",
    "    for img in dataset:\n",
    "        img[img < threshold] = 0\n",
    "        img[img >= threshold] = 255\n",
    "        output.append(img)\n",
    "    return np.array(output, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise(dataset, connectivity):\n",
    "    '''Remove noise surrounding connected component i.e. supposed doodle\n",
    "    :param dataset:\n",
    "    :param connectivity:\n",
    "    '''\n",
    "    output = []\n",
    "    for img in dataset:\n",
    "        img_binary = (img > 0).astype(np.uint8)\n",
    "        nb_components, labels, stats, centroids = cv2.connectedComponentsWithStats(img_binary, connectivity, cv2.CV_32S)\n",
    "        areas = stats[:,-1]\n",
    "        max_label = 1\n",
    "        max_area = areas[1]\n",
    "        for j in range(1, nb_components):\n",
    "            if areas[j] > max_area:\n",
    "                max_label = j\n",
    "                max_area = areas[j]\n",
    "        labels[labels != max_label] = 0\n",
    "        output.append(labels)\n",
    "    return np.array(output, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denoise2(dataset, connectivity):\n",
    "    '''Remove noise surrounding connected component i.e. supposed doodle\n",
    "    :param dataset:\n",
    "    :param connectivity:\n",
    "    '''\n",
    "    output = []\n",
    "    for img in dataset:\n",
    "        img_binary = (img > 0).astype(np.uint8)\n",
    "        nb_components, labels, stats, centroids = cv2.connectedComponentsWithStats(img_binary, connectivity, cv2.CV_32S)\n",
    "        areas = stats[:,-1]\n",
    "        max_label = 1\n",
    "        max_area = areas[1]\n",
    "        for j in range(1, nb_components):\n",
    "            #cv2.rectangle(img, (stats[j,0],stats[j,1]), (stats[j,0]+stats[j,2],stats[j,1]+stats[j,3]), (0,0,255),2)\n",
    "            if areas[j] > max_area:\n",
    "                max_label = j\n",
    "                max_area = areas[j]\n",
    "        labels[labels != max_label] = 0\n",
    "        output.append(labels)\n",
    "    return np.array(output, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(img, dim):\n",
    "    '''Crop image to a square\n",
    "    :param img: image to be cropped\n",
    "    :param dim: height and width of square image\n",
    "    '''\n",
    "    height, width = img.shape\n",
    "    if height > width:\n",
    "        differ = height\n",
    "    else:\n",
    "        differ = width\n",
    "    differ += 4\n",
    "    mask = np.zeros((differ, differ), dtype=\"uint8\")   \n",
    "    x_pos = int((differ-width)/2)\n",
    "    y_pos = int((differ-height)/2)\n",
    "    mask[y_pos:y_pos+height, x_pos:x_pos+width] = img[0:height, 0:width]\n",
    "    mask = cv2.resize(mask, (dim,dim), interpolation=cv2.INTER_AREA)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop(dataset):\n",
    "    '''Crop images to contain supposed doodle\n",
    "    :param dataset:\n",
    "    '''\n",
    "    output = []\n",
    "    for img in dataset:\n",
    "        row_mask = np.all(np.isnan(img) | np.equal(img, 0), axis=1)\n",
    "        col_clean = np.transpose(img[~row_mask])\n",
    "        col_mask = np.all(np.isnan(col_clean) | np.equal(col_clean, 0), axis=1)\n",
    "        new_img = np.transpose(col_clean[~col_mask])\n",
    "        new_img = square(new_img, 100)\n",
    "        output.append(new_img)\n",
    "    return np.array(output, dtype=int)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(original, denoised, cropped, labels, num):\n",
    "    '''Check preprocessing results\n",
    "    :param num: number of randomly selected images to compare preprocessing results\n",
    "    '''\n",
    "    plot = np.random.randint(0,10000,num) # some randomly picked images\n",
    "    #plot = np.array([,,,,,,,,,,,1407]) # some handpicked problematic images\n",
    "    fig = plt.figure(figsize = (12,3*num))\n",
    "    for i in range(len(plot)):\n",
    "        img1 = original[plot[i]]\n",
    "        img2 = denoised[plot[i]]\n",
    "        img3 = cropped[plot[i]]\n",
    "        label = np.array([str(plot[i]), labels[plot[i]][0]])\n",
    "        # plot original image\n",
    "        subplot = fig.add_subplot(num, 3, 3*i+1, title=label)\n",
    "        subplot.imshow(img1, cmap='gray_r')\n",
    "        subplot.axes.get_xaxis().set_visible(False)\n",
    "        subplot.axes.get_yaxis().set_visible(False)\n",
    "        # plot denoised image\n",
    "        subplot = fig.add_subplot(num, 3, 3*i+2, title=label)\n",
    "        subplot.imshow(img2, cmap='gray_r')\n",
    "        subplot.axes.get_xaxis().set_visible(False)\n",
    "        subplot.axes.get_yaxis().set_visible(False)\n",
    "        # plot cropped image\n",
    "        subplot = fig.add_subplot(num, 3, 3*i+3, title=label)\n",
    "        subplot.imshow(img3, cmap='gray_r')\n",
    "        subplot.axes.get_xaxis().set_visible(False)\n",
    "        subplot.axes.get_yaxis().set_visible(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reshape' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-69c03b601707>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# preprocess datasets of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_x0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_x1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtrain_x2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdenoise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'reshape' is not defined"
     ]
    }
   ],
   "source": [
    "# preprocess datasets of images\n",
    "train_x0 = reshape(train_images[:,1])\n",
    "train_x1 = binarize(train_x0, 100)\n",
    "train_x2 = denoise(train_x1, 8)\n",
    "train_x = crop(train_x2)\n",
    "test_x0 = reshape(test_images[:,1])\n",
    "test_x1 = binarize(test_x0, 100)\n",
    "test_x2 = denoise(test_x1, 8)\n",
    "test_x = crop(test_x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check preprocessing results\n",
    "results(train_x0, train_x2, train_x, train_labels, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save preprocessed images\n",
    "#np.save(\"../datasets/train_images_denoised.npy\", prepareToSaveNPY(unravel(train_x2)))\n",
    "#np.save(\"../datasets/test_images_denoised.npy\", prepareToSaveNPY(unravel(test_x2)))\n",
    "#np.save(\"../datasets/train_images_cropped.npy\", prepareToSaveNPY(unravel(train_x)))\n",
    "#np.save(\"../datasets/test_images_cropped.npy\", prepareToSaveNPY(unravel(test_x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RELABELLING IMAGES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the label 'nail' was interpreted in two different ways (i.e. fingernail vs. tool), images with this label in the training set were relabelled to 'nail1' (i.e. fingernail) and 'nail2' (i.e. tool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note number of occurences of 'nail' to see if the proposed task is feasible\n",
    "unique, counts = np.unique(train_labels, return_counts=True)\n",
    "print(dict(zip(unique, counts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note indicies of 'nail' occurences\n",
    "indices_nail = np.where(train_labels == \"nail\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output 'nail' images to manually relabel 'nail1' and 'nail2'\n",
    "fig = plt.figure(figsize = (12,3*4))\n",
    "for i in range(len(indices_nail))[0:12]:\n",
    "    img = train_images[indices_nail[i]]\n",
    "    label = np.array([str(indices_nail[i]), train_labels[indices_nail[i]][0]])\n",
    "    subplot = fig.add_subplot(4, 3, i+1, title=label)\n",
    "    subplot.imshow(img, cmap='gray_r')\n",
    "    subplot.axes.get_xaxis().set_visible(False)\n",
    "    subplot.axes.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note which indicies should be relabelled 'nail1' and 'nail2'\n",
    "indices_nail1 = [38,368,384,478,727]\n",
    "indices_nail2 = [28,101,154,184,214,231,312,346,556,565,722,745]\n",
    "indicies_notsure = [128,324,396,400,446,477,513,518,550,693,749,757]\n",
    "train_y = train_labels\n",
    "for i in indices_nail1:\n",
    "    train_y[i] = \"nail1\"\n",
    "for i in indices_nail2:\n",
    "    train_y[i] = \"nail2\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPANDING TRAINING DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note transformations to expand dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
