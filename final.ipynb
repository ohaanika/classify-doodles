{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "# preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import datasets \n",
    "train_labels = pd.read_csv(\"datasets/train_labels.csv\", delimiter=\",\", header=0, index_col=0)\n",
    "train_images = np.load(\"datasets/train_images.npy\", encoding=\"latin1\")\n",
    "test_images = np.load(\"datasets/train_images.npy\", encoding=\"latin1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store copies, may wish to retrieve original datasets\n",
    "copy_train_labels = np.copy(train_labels)\n",
    "copy_train_images = np.copy(train_images)\n",
    "copy_test_images = np.copy(test_images)\n",
    " \n",
    "# restore original datasets\n",
    "def restore():\n",
    "    train_labels = np.copy(copy_train_labels)\n",
    "    train_images = np.copy(copy_train_images)\n",
    "    test_images = np.copy(copy_test_images)\n",
    "    return train_labels, train_images, test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 1)\n",
      "(10000, 2)\n",
      "(10000, 2)\n"
     ]
    }
   ],
   "source": [
    "# check shape\n",
    "print(train_labels.shape)\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN FROM| FROM HERE IF DATASETS NEED TO BE RESTORED\n",
    "train_labels, train_images, test_images = restore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape labels to 1d array, encode labels to integers\n",
    "train_labels = np.array(train_labels).reshape(-1)\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_labels)\n",
    "train_y = le.transform(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['shovel' 'rifle' 'scorpion' ... 'rollerskates' 'mouth' 'pencil']\n",
      "[25 20 23 ... 21  3 13]\n"
     ]
    }
   ],
   "source": [
    "# check labels\n",
    "print(train_labels)\n",
    "print(train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape images\n",
    "#train_images = train_images[:,1].reshape(-1, 100, 100)\n",
    "train_x = []\n",
    "for i in train_images[:,1]:\n",
    "    train_x.append(i.reshape(100,100))\n",
    "train_x = np.array(train_x, dtype=float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100, 100)\n"
     ]
    }
   ],
   "source": [
    "# check shape\n",
    "print(train_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Noise Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_convolutional_autoencoder():\n",
    "    # encoding\n",
    "    inputs = Input(shape=(28, 28, 1))\n",
    "    x = Conv2D(16, 3, activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D(padding='same')(x)\n",
    "    x = Conv2D( 8, 3, activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D(padding='same')(x)\n",
    "    x = Conv2D( 8, 3, activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D(padding='same')(x)    \n",
    "    \n",
    "    # decoding\n",
    "    x = Conv2D( 8, 3, activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D( 8, 3, activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D()(x)\n",
    "    x = Conv2D(16, 3, activation='relu')(x) # <= padding='valid'!\n",
    "    x = UpSampling2D()(x)\n",
    "    decoded = Conv2D(1, 3, activation='sigmoid', padding='same')(x)    \n",
    "    \n",
    "    # autoencoder\n",
    "    autoencoder = Model(inputs, decoded)\n",
    "    autoencoder.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322\n",
      "322\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1a654bc7f0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "empty_labels = pd.read_csv(\"datasets/empty.csv\", delimiter=\",\")\n",
    "#print(empty_labels)\n",
    "empty_labels =np.array(empty_labels)\n",
    "empty_x = []\n",
    "for n in empty_labels[:, 0]:\n",
    "    empty_x.append(train_x[n])\n",
    "print(len(empty_x))\n",
    "plt.imshow(empty_x[321], cmap='gray')\n",
    "\n",
    "black_x = []\n",
    "black = np.zeros((100, 100))\n",
    "for n in range(322):\n",
    "    black_x.append(black)\n",
    "print(len(black_x))\n",
    "plt.imshow(black_x[321], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "sigmoid_cross_entropy_with_logits() got an unexpected keyword argument 'labels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-db52e34cca9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_convolutional_autoencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m autoencoder.fit(empty_x, black_x, \n\u001b[1;32m      3\u001b[0m                 \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 batch_size=128)\n",
      "\u001b[0;32m<ipython-input-52-cb97f5919a6c>\u001b[0m in \u001b[0;36mmake_convolutional_autoencoder\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# autoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mautoencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mautoencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m                     output_loss = weighted_loss(y_true, y_pred,\n\u001b[0;32m--> 342\u001b[0;31m                                                 sample_weight, mask)\n\u001b[0m\u001b[1;32m    343\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.7/site-packages/keras/losses.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbinary_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_crossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py36/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mbinary_crossentropy\u001b[0;34m(target, output, from_logits)\u001b[0m\n\u001b[1;32m   3377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3378\u001b[0m     return tf.nn.sigmoid_cross_entropy_with_logits(labels=target,\n\u001b[0;32m-> 3379\u001b[0;31m                                                    logits=output)\n\u001b[0m\u001b[1;32m   3380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: sigmoid_cross_entropy_with_logits() got an unexpected keyword argument 'labels'"
     ]
    }
   ],
   "source": [
    "\n",
    "autoencoder = make_convolutional_autoencoder()\n",
    "autoencoder.fit(empty_x, black_x, \n",
    "                epochs=50, \n",
    "                batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.12.0'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
